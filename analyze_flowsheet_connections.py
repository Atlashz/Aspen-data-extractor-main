#!/usr/bin/env python3
"""
ä¸“é—¨è§£æaspen_flowsheet.xlsxæ–‡ä»¶ä¸­çš„è®¾å¤‡å’Œæµè‚¡è¿æ¥ä¿¡æ¯

æ ¹æ®ä¹‹å‰çš„åˆ†æï¼Œæ–‡ä»¶ç»“æ„å¦‚ä¸‹ï¼š
- ç¬¬2è¡Œï¼š'Material'
- ç¬¬3è¡Œï¼š'Stream Name' + æµè‚¡åç§°
- ç¬¬4è¡Œï¼š'Description'
- ç¬¬5è¡Œï¼š'From' + æºè®¾å¤‡
- ç¬¬6è¡Œï¼š'To' + ç›®æ ‡è®¾å¤‡

Author: æµè‚¡è¿æ¥åˆ†æå·¥å…·
Date: 2025-07-27
"""

import pandas as pd
import logging
from pathlib import Path
from typing import Dict, List, Tuple

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class FlowsheetConnectionAnalyzer:
    """åˆ†æflowsheetä¸­çš„è®¾å¤‡å’Œæµè‚¡è¿æ¥å…³ç³»"""
    
    def __init__(self, file_path: str):
        self.file_path = file_path
        self.df = None
        self.stream_connections = {}
        self.equipment_connections = {}
        
    def load_data(self):
        """åŠ è½½Excelæ•°æ®"""
        try:
            self.df = pd.read_excel(self.file_path, sheet_name='Aspen Data Tables')
            logger.info(f"âœ… æˆåŠŸåŠ è½½æ•°æ®: {self.df.shape}")
            return True
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {str(e)}")
            return False
    
    def parse_stream_connections(self):
        """è§£ææµè‚¡è¿æ¥ä¿¡æ¯"""
        if self.df is None:
            logger.error("âŒ æ•°æ®æœªåŠ è½½")
            return
        
        logger.info("ğŸ” è§£ææµè‚¡è¿æ¥ä¿¡æ¯...")
        
        # æ‰¾åˆ°å…³é”®è¡Œ
        stream_name_row = None
        from_row = None
        to_row = None
        
        for idx, row in self.df.iterrows():
            first_col_value = str(row.iloc[2]) if pd.notna(row.iloc[2]) else ""
            
            if first_col_value == "Stream Name":
                stream_name_row = idx
                logger.info(f"  ğŸ“‹ æ‰¾åˆ°æµè‚¡åç§°è¡Œ: {idx}")
            elif first_col_value == "From":
                from_row = idx
                logger.info(f"  ğŸ“ æ‰¾åˆ°æºè®¾å¤‡è¡Œ: {idx}")
            elif first_col_value == "To":
                to_row = idx
                logger.info(f"  ğŸ“ æ‰¾åˆ°ç›®æ ‡è®¾å¤‡è¡Œ: {idx}")
        
        if not all([stream_name_row is not None, from_row is not None, to_row is not None]):
            logger.error("âŒ æ‰¾ä¸åˆ°å¿…è¦çš„è¡Œä¿¡æ¯")
            return
        
        # æå–æµè‚¡è¿æ¥ä¿¡æ¯
        stream_names = []
        from_equipment = []
        to_equipment = []
        
        # ä»åˆ—3å¼€å§‹æå–æ•°æ®ï¼ˆè·³è¿‡å‰3åˆ—æ ‡é¢˜åˆ—ï¼‰
        for col_idx in range(3, len(self.df.columns)):
            stream_name = str(self.df.iloc[stream_name_row, col_idx]) if pd.notna(self.df.iloc[stream_name_row, col_idx]) else None
            from_eq = str(self.df.iloc[from_row, col_idx]) if pd.notna(self.df.iloc[from_row, col_idx]) else None
            to_eq = str(self.df.iloc[to_row, col_idx]) if pd.notna(self.df.iloc[to_row, col_idx]) else None
            
            # è¿‡æ»¤æ‰æ— æ•ˆæ•°æ®
            if stream_name and stream_name != 'nan' and stream_name != '':
                stream_names.append(stream_name)
                from_equipment.append(from_eq if from_eq and from_eq != 'nan' else None)
                to_equipment.append(to_eq if to_eq and to_eq != 'nan' else None)
        
        # æ„å»ºè¿æ¥å­—å…¸
        for i, stream_name in enumerate(stream_names):
            self.stream_connections[stream_name] = {
                'from': from_equipment[i],
                'to': to_equipment[i]
            }
        
        logger.info(f"âœ… è§£æäº† {len(self.stream_connections)} ä¸ªæµè‚¡è¿æ¥")
        
        return self.stream_connections
    
    def build_equipment_connections(self):
        """æ„å»ºè®¾å¤‡è¿æ¥å…³ç³»"""
        if not self.stream_connections:
            logger.error("âŒ æµè‚¡è¿æ¥ä¿¡æ¯æœªè§£æ")
            return
        
        logger.info("ğŸ”§ æ„å»ºè®¾å¤‡è¿æ¥å…³ç³»...")
        
        # åˆå§‹åŒ–è®¾å¤‡è¿æ¥å­—å…¸
        all_equipment = set()
        for stream_info in self.stream_connections.values():
            if stream_info['from']:
                all_equipment.add(stream_info['from'])
            if stream_info['to']:
                all_equipment.add(stream_info['to'])
        
        # ä¸ºæ¯ä¸ªè®¾å¤‡åˆ›å»ºè¿æ¥ä¿¡æ¯
        for equipment in all_equipment:
            self.equipment_connections[equipment] = {
                'inlet_streams': [],
                'outlet_streams': []
            }
        
        # å¡«å……è¿æ¥ä¿¡æ¯
        for stream_name, stream_info in self.stream_connections.items():
            from_eq = stream_info['from']
            to_eq = stream_info['to']
            
            # å¯¹äºæºè®¾å¤‡ï¼Œè¿™æ˜¯å‡ºæ–™æµè‚¡
            if from_eq and from_eq in self.equipment_connections:
                self.equipment_connections[from_eq]['outlet_streams'].append(stream_name)
            
            # å¯¹äºç›®æ ‡è®¾å¤‡ï¼Œè¿™æ˜¯è¿›æ–™æµè‚¡
            if to_eq and to_eq in self.equipment_connections:
                self.equipment_connections[to_eq]['inlet_streams'].append(stream_name)
        
        logger.info(f"âœ… æ„å»ºäº† {len(self.equipment_connections)} ä¸ªè®¾å¤‡çš„è¿æ¥å…³ç³»")
        
        return self.equipment_connections
    
    def print_analysis_results(self):
        """æ‰“å°åˆ†æç»“æœ"""
        print("\n" + "="*80)
        print("ğŸŒŠ æµè‚¡è¿æ¥åˆ†æç»“æœ")
        print("="*80)
        
        if self.stream_connections:
            print(f"\nğŸ“Š å‘ç° {len(self.stream_connections)} ä¸ªæµè‚¡:")
            for stream_name, connection in self.stream_connections.items():
                from_info = f"ä» {connection['from']}" if connection['from'] else "æœªçŸ¥æº"
                to_info = f"åˆ° {connection['to']}" if connection['to'] else "æœªçŸ¥ç›®æ ‡"
                print(f"  ğŸŒŠ {stream_name:12s}: {from_info:15s} â†’ {to_info}")
        
        print("\n" + "="*80)
        print("ğŸ­ è®¾å¤‡è¿æ¥åˆ†æç»“æœ")
        print("="*80)
        
        if self.equipment_connections:
            print(f"\nğŸ“Š å‘ç° {len(self.equipment_connections)} ä¸ªè®¾å¤‡:")
            for equipment, connections in self.equipment_connections.items():
                inlet_count = len(connections['inlet_streams'])
                outlet_count = len(connections['outlet_streams'])
                print(f"\nğŸ­ {equipment}:")
                print(f"  ğŸ“¥ è¿›æ–™æµè‚¡ ({inlet_count}): {', '.join(connections['inlet_streams']) if connections['inlet_streams'] else 'æ— '}")
                print(f"  ğŸ“¤ å‡ºæ–™æµè‚¡ ({outlet_count}): {', '.join(connections['outlet_streams']) if connections['outlet_streams'] else 'æ— '}")
    
    def get_equipment_stream_summary(self):
        """è·å–è®¾å¤‡æµè‚¡è¿æ¥æ‘˜è¦"""
        summary = {}
        
        if self.equipment_connections:
            for equipment, connections in self.equipment_connections.items():
                summary[equipment] = {
                    'inlet_count': len(connections['inlet_streams']),
                    'outlet_count': len(connections['outlet_streams']),
                    'inlet_streams': connections['inlet_streams'],
                    'outlet_streams': connections['outlet_streams']
                }
        
        return summary
    
    def export_connections_to_json(self, output_file: str = "flowsheet_connections.json"):
        """å¯¼å‡ºè¿æ¥ä¿¡æ¯åˆ°JSONæ–‡ä»¶"""
        import json
        
        export_data = {
            'timestamp': pd.Timestamp.now().isoformat(),
            'source_file': self.file_path,
            'stream_connections': self.stream_connections,
            'equipment_connections': self.equipment_connections,
            'summary': {
                'total_streams': len(self.stream_connections),
                'total_equipment': len(self.equipment_connections),
                'equipment_summary': self.get_equipment_stream_summary()
            }
        }
        
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)
            logger.info(f"âœ… è¿æ¥ä¿¡æ¯å·²å¯¼å‡ºåˆ°: {output_file}")
        except Exception as e:
            logger.error(f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    file_path = "aspen_flowsheet.xlsx"
    
    logger.info("=" * 80)
    logger.info("ğŸš€ å¼€å§‹åˆ†æ Aspen Flowsheet è¿æ¥ä¿¡æ¯")
    logger.info("=" * 80)
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = FlowsheetConnectionAnalyzer(file_path)
    
    # åŠ è½½æ•°æ®
    if not analyzer.load_data():
        return
    
    # è§£ææµè‚¡è¿æ¥
    stream_connections = analyzer.parse_stream_connections()
    if not stream_connections:
        logger.error("âŒ æµè‚¡è¿æ¥è§£æå¤±è´¥")
        return
    
    # æ„å»ºè®¾å¤‡è¿æ¥
    equipment_connections = analyzer.build_equipment_connections()
    if not equipment_connections:
        logger.error("âŒ è®¾å¤‡è¿æ¥æ„å»ºå¤±è´¥")
        return
    
    # æ‰“å°ç»“æœ
    analyzer.print_analysis_results()
    
    # å¯¼å‡ºç»“æœ
    analyzer.export_connections_to_json()
    
    logger.info("\n" + "=" * 80)
    logger.info("âœ… æµè‚¡è¿æ¥åˆ†æå®Œæˆ!")
    logger.info("=" * 80)

if __name__ == "__main__":
    main()
