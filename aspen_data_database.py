#!/usr/bin/env python3
"""
Aspen Data Database Manager

ç”¨äºå­˜å‚¨å’Œç®¡ç†ä» Aspen Plus æå–çš„å·¥è‰ºæ•°æ®çš„æ•°æ®åº“ç³»ç»Ÿã€‚
æ”¯æŒæ¯æ¬¡è¿è¡Œæ—¶è¦†ç›–ä¹‹å‰çš„æ•°æ®ï¼Œä¸ºåç»­çš„ TEA è®¡ç®—æä¾›å¿«é€Ÿæ•°æ®è®¿é—®ã€‚

Features:
- SQLite æ•°æ®åº“å­˜å‚¨
- ç»“æ„åŒ–æ•°æ®æ¨¡å‹
- æ•°æ®ç‰ˆæœ¬æ§åˆ¶
- å¿«é€ŸæŸ¥è¯¢æ¥å£
- å®Œæ•´çš„å¤‡ä»½å’Œæ¢å¤åŠŸèƒ½
- Enhanced I-N column support for heat exchangers

Author: TEA Analysis Framework
Date: 2025-07-26
Version: 1.1 - Enhanced I-N Column Support
"""

import sqlite3
import json
import os
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
import pandas as pd

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')
logger = logging.getLogger(__name__)

@dataclass
class AspenStreamRecord:
    """Aspen æµè‚¡æ•°æ®è®°å½•"""
    name: str
    temperature: float
    pressure: float
    mass_flow: float
    volume_flow: float
    molar_flow: float
    composition: str  # JSON string of composition dict
    extraction_time: str

@dataclass
class AspenEquipmentRecord:
    """Aspen è®¾å¤‡æ•°æ®è®°å½•"""
    name: str
    equipment_type: str
    aspen_type: str
    importance: str
    function: str
    parameters: str  # JSON string of parameters dict
    parameter_count: int
    excel_specified: bool
    extraction_time: str

@dataclass
class HeatExchangerRecord:
    """æ¢çƒ­å™¨æ•°æ®è®°å½• - Enhanced with I-N column support"""
    name: str
    duty_kw: float
    area_m2: float
    temperatures: str  # JSON string
    pressures: str     # JSON string
    source: str  # 'excel' or 'aspen'
    extraction_time: str
    # I-N column data
    column_i_data: Optional[float] = None
    column_i_header: Optional[str] = None
    column_j_data: Optional[float] = None
    column_j_header: Optional[str] = None
    column_k_data: Optional[float] = None
    column_k_header: Optional[str] = None
    column_l_data: Optional[float] = None
    column_l_header: Optional[str] = None
    column_m_data: Optional[float] = None
    column_m_header: Optional[str] = None
    column_n_data: Optional[float] = None
    column_n_header: Optional[str] = None
    columns_i_to_n_raw: Optional[str] = None  # JSON string of raw I-N data

@dataclass
class ExtractionSession:
    """æ•°æ®æå–ä¼šè¯è®°å½•"""
    session_id: str
    extraction_time: str
    aspen_file_path: str
    hex_file_path: str
    stream_count: int
    equipment_count: int
    hex_count: int
    total_heat_duty_kw: float
    total_heat_area_m2: float
    status: str
    notes: str

class AspenDataDatabase:
    """Aspen æ•°æ®æ•°æ®åº“ç®¡ç†å™¨ - Enhanced with I-N column support"""
    
    def __init__(self, db_path: str = "aspen_data.db"):
        self.db_path = db_path
        self.connection = None
        self.current_session_id = None
        
        # åˆå§‹åŒ–æ•°æ®åº“
        self._initialize_database()
        
    def _initialize_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
        try:
            self.connection = sqlite3.connect(self.db_path)
            self.connection.row_factory = sqlite3.Row  # å…è®¸æŒ‰åˆ—åè®¿é—®
            
            # åˆ›å»ºè¡¨ç»“æ„
            self._create_tables()
            
            logger.info(f"âœ… Database initialized: {self.db_path}")
            
        except Exception as e:
            logger.error(f"Failed to initialize database: {e}")
            raise
    
    def _create_tables(self):
        """åˆ›å»ºæ•°æ®åº“è¡¨"""
        cursor = self.connection.cursor()
        
        # æ•°æ®æå–ä¼šè¯è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS extraction_sessions (
                session_id TEXT PRIMARY KEY,
                extraction_time TEXT NOT NULL,
                aspen_file_path TEXT,
                hex_file_path TEXT,
                stream_count INTEGER DEFAULT 0,
                equipment_count INTEGER DEFAULT 0,
                hex_count INTEGER DEFAULT 0,
                total_heat_duty_kw REAL DEFAULT 0.0,
                total_heat_area_m2 REAL DEFAULT 0.0,
                status TEXT DEFAULT 'active',
                notes TEXT
            )
        """)
        
        # æµè‚¡æ•°æ®è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS aspen_streams (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT NOT NULL,
                name TEXT NOT NULL,
                temperature REAL,
                pressure REAL,
                mass_flow REAL,
                volume_flow REAL,
                molar_flow REAL,
                composition TEXT,
                extraction_time TEXT,
                stream_category TEXT,
                stream_sub_category TEXT,
                classification_confidence REAL,
                classification_reasoning TEXT,
                custom_name TEXT,
                FOREIGN KEY (session_id) REFERENCES extraction_sessions (session_id)
            )
        """)
        
        # è®¾å¤‡æ•°æ®è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS aspen_equipment (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT NOT NULL,
                name TEXT NOT NULL,
                equipment_type TEXT,
                aspen_type TEXT,
                importance TEXT,
                function TEXT,
                parameters TEXT,
                parameter_count INTEGER DEFAULT 0,
                excel_specified BOOLEAN DEFAULT 0,
                extraction_time TEXT,
                custom_name TEXT,
                FOREIGN KEY (session_id) REFERENCES extraction_sessions (session_id)
            )
        """)
        
        # æ¢çƒ­å™¨æ•°æ®è¡¨ - Enhanced with hot/cold stream data and I-N column support
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS heat_exchangers (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT NOT NULL,
                name TEXT NOT NULL,
                duty_kw REAL DEFAULT 0.0,
                area_m2 REAL DEFAULT 0.0,
                temperatures TEXT,
                pressures TEXT,
                source TEXT DEFAULT 'unknown',
                extraction_time TEXT,
                hot_stream_name TEXT,
                hot_stream_inlet_temp REAL,
                hot_stream_outlet_temp REAL,
                hot_stream_flow_rate REAL,
                hot_stream_composition TEXT,
                cold_stream_name TEXT,
                cold_stream_inlet_temp REAL,
                cold_stream_outlet_temp REAL,
                cold_stream_flow_rate REAL,
                cold_stream_composition TEXT,
                column_i_data REAL,
                column_i_header TEXT,
                column_j_data REAL,
                column_j_header TEXT,
                column_k_data REAL,
                column_k_header TEXT,
                column_l_data REAL,
                column_l_header TEXT,
                column_m_data REAL,
                column_m_header TEXT,
                column_n_data REAL,
                column_n_header TEXT,
                columns_i_to_n_raw TEXT,
                FOREIGN KEY (session_id) REFERENCES extraction_sessions (session_id)
            )
        """)
        
        # åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_streams_name ON aspen_streams(name)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_equipment_name ON aspen_equipment(name)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_equipment_type ON aspen_equipment(equipment_type)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_hex_name ON heat_exchangers(name)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_session_time ON extraction_sessions(extraction_time)")
        
        self.connection.commit()
        logger.info("Database tables created successfully with I-N column support")
    
    def start_new_session(self, aspen_file: str = None, hex_file: str = None) -> str:
        """å¼€å§‹æ–°çš„æ•°æ®æå–ä¼šè¯"""
        # ç”Ÿæˆä¼šè¯ID
        session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.current_session_id = session_id
        
        # æ¸…ç©ºç°æœ‰æ•°æ®ï¼ˆè¦†ç›–æ¨¡å¼ï¼‰
        self._clear_all_data()
        
        # åˆ›å»ºæ–°ä¼šè¯è®°å½•
        cursor = self.connection.cursor()
        cursor.execute("""
            INSERT INTO extraction_sessions 
            (session_id, extraction_time, aspen_file_path, hex_file_path, status, notes)
            VALUES (?, ?, ?, ?, ?, ?)
        """, (
            session_id,
            datetime.now().isoformat(),
            aspen_file,
            hex_file,
            'active',
            'New extraction session started'
        ))
        
        self.connection.commit()
        logger.info(f"âœ… New extraction session started: {session_id}")
        
        return session_id
    
    def _clear_all_data(self):
        """æ¸…ç©ºæ‰€æœ‰æ•°æ®è¡¨ï¼ˆè¦†ç›–æ¨¡å¼ï¼‰"""
        cursor = self.connection.cursor()
        
        # åˆ é™¤æ‰€æœ‰æ•°æ®
        cursor.execute("DELETE FROM heat_exchangers")
        cursor.execute("DELETE FROM aspen_equipment") 
        cursor.execute("DELETE FROM aspen_streams")
        cursor.execute("DELETE FROM extraction_sessions")
        
        self.connection.commit()
        logger.info("ğŸ—‘ï¸ All existing data cleared")
    
    def store_stream_data(self, streams: Dict[str, Any]):
        """å­˜å‚¨æµè‚¡æ•°æ®"""
        if not self.current_session_id:
            raise ValueError("No active session. Call start_new_session() first.")
        
        cursor = self.connection.cursor()
        extraction_time = datetime.now().isoformat()
        
        for stream_name, stream_data in streams.items():
            # å¤„ç†ç»„æˆæ•°æ®
            composition_json = json.dumps(stream_data.get('composition', {}))
            
            cursor.execute("""
                INSERT INTO aspen_streams 
                (session_id, name, temperature, pressure, mass_flow, volume_flow, 
                 molar_flow, composition, extraction_time, stream_category, 
                 stream_sub_category, classification_confidence, custom_name)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                self.current_session_id,
                stream_name,
                stream_data.get('temperature', 0.0),
                stream_data.get('pressure', 0.0),
                stream_data.get('mass_flow', 0.0),
                stream_data.get('volume_flow', 0.0),
                stream_data.get('molar_flow', 0.0),
                composition_json,
                extraction_time,
                stream_data.get('stream_category', None),
                stream_data.get('stream_sub_category', None),
                stream_data.get('classification_confidence', None),
                stream_data.get('custom_name', None)
            ))
        
        self.connection.commit()
        logger.info(f"âœ… Stored {len(streams)} stream records")
    
    def store_equipment_data(self, equipment: Dict[str, Any]):
        """å­˜å‚¨è®¾å¤‡æ•°æ®"""
        if not self.current_session_id:
            raise ValueError("No active session. Call start_new_session() first.")
        
        cursor = self.connection.cursor()
        extraction_time = datetime.now().isoformat()
        
        for eq_name, eq_data in equipment.items():
            # å¤„ç†å‚æ•°æ•°æ®
            parameters_json = json.dumps(eq_data.get('parameters', {}))
            
            cursor.execute("""
                INSERT INTO aspen_equipment 
                (session_id, name, equipment_type, aspen_type, importance, 
                 function, parameters, parameter_count, excel_specified, extraction_time, custom_name)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                self.current_session_id,
                eq_name,
                eq_data.get('type', 'Unknown'),
                eq_data.get('aspen_type', 'Unknown'),
                eq_data.get('importance', 'Unknown'),
                eq_data.get('function', 'Unknown'),
                parameters_json,
                eq_data.get('parameter_count', 0),
                eq_data.get('excel_specified', False),
                extraction_time,
                eq_data.get('custom_name', None)
            ))
        
        self.connection.commit()
        logger.info(f"âœ… Stored {len(equipment)} equipment records")
    
    def store_hex_data(self, hex_data: Dict[str, Any]):
        """å­˜å‚¨æ¢çƒ­å™¨æ•°æ® - Enhanced with I-N column support"""
        if not self.current_session_id:
            raise ValueError("No active session. Call start_new_session() first.")
        
        cursor = self.connection.cursor()
        extraction_time = datetime.now().isoformat()
        
        heat_exchangers = hex_data.get('heat_exchangers', [])
        
        for hex_info in heat_exchangers:
            cursor.execute("""
                INSERT INTO heat_exchangers 
                (session_id, name, duty_kw, area_m2, temperatures, pressures, source, extraction_time,
                 hot_stream_name, hot_stream_inlet_temp, hot_stream_outlet_temp, hot_stream_flow_rate, hot_stream_composition,
                 cold_stream_name, cold_stream_inlet_temp, cold_stream_outlet_temp, cold_stream_flow_rate, cold_stream_composition,
                 column_i_data, column_i_header, column_j_data, column_j_header, 
                 column_k_data, column_k_header, column_l_data, column_l_header,
                 column_m_data, column_m_header, column_n_data, column_n_header, columns_i_to_n_raw)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                self.current_session_id,
                hex_info.get('name', 'Unknown'),
                hex_info.get('duty', 0.0),
                hex_info.get('area', 0.0),
                json.dumps(hex_info.get('temperatures', {})),
                json.dumps(hex_info.get('pressures', {})),
                'excel',
                extraction_time,
                hex_info.get('hot_stream_name', None),
                hex_info.get('hot_stream_inlet_temp', None),
                hex_info.get('hot_stream_outlet_temp', None),
                hex_info.get('hot_stream_flow_rate', None),
                json.dumps(hex_info.get('hot_stream_composition', {})) if hex_info.get('hot_stream_composition') else None,
                hex_info.get('cold_stream_name', None),
                hex_info.get('cold_stream_inlet_temp', None),
                hex_info.get('cold_stream_outlet_temp', None),
                hex_info.get('cold_stream_flow_rate', None),
                json.dumps(hex_info.get('cold_stream_composition', {})) if hex_info.get('cold_stream_composition') else None,
                # I-N column data
                hex_info.get('column_i_data', None),
                hex_info.get('column_i_header', None),
                hex_info.get('column_j_data', None),
                hex_info.get('column_j_header', None),
                hex_info.get('column_k_data', None),
                hex_info.get('column_k_header', None),
                hex_info.get('column_l_data', None),
                hex_info.get('column_l_header', None),
                hex_info.get('column_m_data', None),
                hex_info.get('column_m_header', None),
                hex_info.get('column_n_data', None),
                hex_info.get('column_n_header', None),
                json.dumps(hex_info.get('columns_i_to_n_raw', {})) if hex_info.get('columns_i_to_n_raw') else None
            ))
        
        self.connection.commit()
        logger.info(f"âœ… Stored {len(heat_exchangers)} heat exchanger records with I-N column data")
    
    def finalize_session(self, summary_stats: Dict[str, Any]):
        """å®Œæˆå½“å‰ä¼šè¯å¹¶æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        if not self.current_session_id:
            return
        
        cursor = self.connection.cursor()
        
        cursor.execute("""
            UPDATE extraction_sessions 
            SET stream_count = ?, equipment_count = ?, hex_count = ?,
                total_heat_duty_kw = ?, total_heat_area_m2 = ?, status = ?, notes = ?
            WHERE session_id = ?
        """, (
            summary_stats.get('stream_count', 0),
            summary_stats.get('equipment_count', 0),
            summary_stats.get('hex_count', 0),
            summary_stats.get('total_heat_duty_kw', 0.0),
            summary_stats.get('total_heat_area_m2', 0.0),
            'completed',
            f"Extraction completed successfully at {datetime.now().isoformat()}",
            self.current_session_id
        ))
        
        self.connection.commit()
        logger.info(f"âœ… Session finalized: {self.current_session_id}")
    
    def get_latest_session_id(self) -> Optional[str]:
        """è·å–æœ€æ–°çš„ä¼šè¯ID"""
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT session_id FROM extraction_sessions 
            ORDER BY extraction_time DESC LIMIT 1
        """)
        
        result = cursor.fetchone()
        return result['session_id'] if result else None
    
    def get_all_streams(self, session_id: str = None) -> pd.DataFrame:
        """è·å–æ‰€æœ‰æµè‚¡æ•°æ®"""
        if not session_id:
            session_id = self.get_latest_session_id()
        
        if not session_id:
            logger.warning("No session found")
            return pd.DataFrame()
        
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT * FROM aspen_streams WHERE session_id = ?
            ORDER BY name
        """, (session_id,))
        
        rows = cursor.fetchall()
        df = pd.DataFrame([dict(row) for row in rows])
        
        # è§£æç»„æˆæ•°æ®
        if not df.empty and 'composition' in df.columns:
            df['composition_dict'] = df['composition'].apply(
                lambda x: json.loads(x) if x else {}
            )
        
        logger.info(f"Retrieved {len(df)} stream records")
        return df
    
    def get_all_equipment(self, session_id: str = None) -> pd.DataFrame:
        """è·å–æ‰€æœ‰è®¾å¤‡æ•°æ®"""
        if not session_id:
            session_id = self.get_latest_session_id()
        
        if not session_id:
            logger.warning("No session found")
            return pd.DataFrame()
        
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT * FROM aspen_equipment WHERE session_id = ?
            ORDER BY name
        """, (session_id,))
        
        rows = cursor.fetchall()
        df = pd.DataFrame([dict(row) for row in rows])
        
        # è§£æå‚æ•°æ•°æ®
        if not df.empty and 'parameters' in df.columns:
            df['parameters_dict'] = df['parameters'].apply(
                lambda x: json.loads(x) if x else {}
            )
        
        logger.info(f"Retrieved {len(df)} equipment records")
        return df
    
    def get_all_heat_exchangers(self, session_id: str = None) -> pd.DataFrame:
        """è·å–æ‰€æœ‰æ¢çƒ­å™¨æ•°æ® - Enhanced with I-N column data"""
        if not session_id:
            session_id = self.get_latest_session_id()
        
        if not session_id:
            logger.warning("No session found")
            return pd.DataFrame()
        
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT * FROM heat_exchangers WHERE session_id = ?
            ORDER BY name
        """, (session_id,))
        
        rows = cursor.fetchall()
        df = pd.DataFrame([dict(row) for row in rows])
        
        # Parse composition and I-N column data
        if not df.empty:
            if 'hot_stream_composition' in df.columns:
                df['hot_stream_composition_dict'] = df['hot_stream_composition'].apply(
                    lambda x: json.loads(x) if x else {}
                )
            if 'cold_stream_composition' in df.columns:
                df['cold_stream_composition_dict'] = df['cold_stream_composition'].apply(
                    lambda x: json.loads(x) if x else {}
                )
            if 'columns_i_to_n_raw' in df.columns:
                df['columns_i_to_n_raw_dict'] = df['columns_i_to_n_raw'].apply(
                    lambda x: json.loads(x) if x else {}
                )
        
        logger.info(f"Retrieved {len(df)} heat exchanger records with I-N column data")
        return df
    
    def get_i_to_n_column_summary(self, session_id: str = None) -> Dict[str, Any]:
        """è·å–I-Nåˆ—æ•°æ®æ±‡æ€»ç»Ÿè®¡"""
        if not session_id:
            session_id = self.get_latest_session_id()
        
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT 
                COUNT(*) as total_hex,
                COUNT(column_i_data) as column_i_count,
                COUNT(column_j_data) as column_j_count,
                COUNT(column_k_data) as column_k_count,
                COUNT(column_l_data) as column_l_count,
                COUNT(column_m_data) as column_m_count,
                COUNT(column_n_data) as column_n_count,
                AVG(column_i_data) as avg_column_i,
                AVG(column_j_data) as avg_column_j,
                AVG(column_k_data) as avg_column_k,
                AVG(column_l_data) as avg_column_l,
                AVG(column_m_data) as avg_column_m,
                AVG(column_n_data) as avg_column_n
            FROM heat_exchangers 
            WHERE session_id = ?
        """, (session_id,))
        
        result = cursor.fetchone()
        return dict(result) if result else {}
    
    def get_database_summary(self) -> Dict[str, Any]:
        """è·å–æ•°æ®åº“æ‘˜è¦ä¿¡æ¯"""
        cursor = self.connection.cursor()
        
        # è·å–æœ€æ–°ä¼šè¯ä¿¡æ¯
        cursor.execute("""
            SELECT * FROM extraction_sessions 
            ORDER BY extraction_time DESC LIMIT 1
        """)
        latest_session = cursor.fetchone()
        
        if not latest_session:
            return {"status": "empty", "message": "No data in database"}
        
        session_dict = dict(latest_session)
        
        # ç»Ÿè®¡å„è¡¨æ•°æ®é‡
        cursor.execute("SELECT COUNT(*) as count FROM aspen_streams WHERE session_id = ?", 
                      (session_dict['session_id'],))
        stream_count = cursor.fetchone()['count']
        
        cursor.execute("SELECT COUNT(*) as count FROM aspen_equipment WHERE session_id = ?", 
                      (session_dict['session_id'],))
        equipment_count = cursor.fetchone()['count']
        
        cursor.execute("SELECT COUNT(*) as count FROM heat_exchangers WHERE session_id = ?", 
                      (session_dict['session_id'],))
        hex_count = cursor.fetchone()['count']
        
        # I-N column data coverage
        i_to_n_summary = self.get_i_to_n_column_summary(session_dict['session_id'])
        
        return {
            "status": "active",
            "latest_session": session_dict,
            "record_counts": {
                "streams": stream_count,
                "equipment": equipment_count,
                "heat_exchangers": hex_count
            },
            "i_to_n_column_coverage": i_to_n_summary,
            "database_path": self.db_path,
            "total_records": stream_count + equipment_count + hex_count
        }
    
    def export_to_json(self, output_file: str = None, session_id: str = None):
        """å¯¼å‡ºæ•°æ®åº“å†…å®¹åˆ°JSONæ–‡ä»¶"""
        if not output_file:
            output_file = f"excel_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        if not session_id:
            session_id = self.get_latest_session_id()
        
        if not session_id:
            logger.error("No session found for export")
            return False
        
        try:
            # è·å–æ‰€æœ‰æ•°æ®
            streams_df = self.get_all_streams(session_id)
            equipment_df = self.get_all_equipment(session_id)
            hex_df = self.get_all_heat_exchangers(session_id)
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            export_data = {
                "session_id": session_id,
                "export_time": datetime.now().isoformat(),
                "streams": streams_df.to_dict('records') if not streams_df.empty else [],
                "equipment": equipment_df.to_dict('records') if not equipment_df.empty else [],
                "heat_exchangers": hex_df.to_dict('records') if not hex_df.empty else [],
                "i_to_n_column_summary": self.get_i_to_n_column_summary(session_id),
                "summary": self.get_database_summary()
            }
            
            # å†™å…¥JSONæ–‡ä»¶
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"âœ… Database exported to {output_file}")
            return True
            
        except Exception as e:
            logger.error(f"Export failed: {e}")
            return False
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.connection:
            self.connection.close()
            logger.info("Database connection closed")


def test_database_system():
    """æµ‹è¯•æ•°æ®åº“ç³»ç»Ÿ - Enhanced with I-N column testing"""
    print("\n" + "="*60)
    print("ğŸ§ª ASPEN DATA DATABASE SYSTEM TEST - I-N Column Enhanced")
    print("="*60)
    
    # åˆ›å»ºæ•°æ®åº“å®ä¾‹
    db = AspenDataDatabase("test_aspen_data.db")
    
    try:
        # 1. æµ‹è¯•ä¼šè¯åˆ›å»º
        print("\n1ï¸âƒ£ Testing Session Management:")
        session_id = db.start_new_session("test.apw", "BFG-CO2H-HEX.xlsx")
        print(f"   âœ… Session created: {session_id}")
        
        # 2. æµ‹è¯•æ•°æ®å­˜å‚¨
        print("\n2ï¸âƒ£ Testing Data Storage:")
        
        # æ¨¡æ‹Ÿæ¢çƒ­å™¨æ•°æ® - With I-N column data
        test_hex = {
            "heat_exchangers": [
                {
                    "name": "HEX-001",
                    "duty": 500.0,
                    "area": 125.0,
                    "temperatures": {"hot_in": 200, "hot_out": 150},
                    "pressures": {"shell": 20, "tube": 15},
                    # I-N column data
                    "column_i_data": 200.5,
                    "column_i_header": "Hot Inlet Temp (Â°C)",
                    "column_j_data": 150.2,
                    "column_j_header": "Hot Outlet Temp (Â°C)",
                    "column_k_data": 30.0,
                    "column_k_header": "Cold Inlet Temp (Â°C)",
                    "column_l_data": 80.5,
                    "column_l_header": "Cold Outlet Temp (Â°C)",
                    "column_m_data": 1000.0,
                    "column_m_header": "Hot Flow Rate (kg/h)",
                    "column_n_data": 1200.0,
                    "column_n_header": "Cold Flow Rate (kg/h)",
                    "columns_i_to_n_raw": {
                        "I": 200.5, "J": 150.2, "K": 30.0, 
                        "L": 80.5, "M": 1000.0, "N": 1200.0
                    }
                }
            ]
        }
        
        db.store_hex_data(test_hex)
        print(f"   âœ… Stored {len(test_hex['heat_exchangers'])} heat exchanger records with I-N data")
        
        # 3. æµ‹è¯•æ•°æ®æ£€ç´¢
        print("\n3ï¸âƒ£ Testing Data Retrieval:")
        
        hex_df = db.get_all_heat_exchangers()
        print(f"   âœ… Retrieved {len(hex_df)} heat exchanger records")
        
        # 4. æµ‹è¯•I-Nåˆ—æ•°æ®æ±‡æ€»
        print("\n4ï¸âƒ£ Testing I-N Column Summary:")
        i_to_n_summary = db.get_i_to_n_column_summary()
        print(f"   âœ… I-N Column Coverage:")
        for key, value in i_to_n_summary.items():
            print(f"      {key}: {value}")
        
        # 5. å®Œæˆä¼šè¯
        summary_stats = {
            "stream_count": 0,
            "equipment_count": 0,
            "hex_count": len(test_hex['heat_exchangers']),
            "total_heat_duty_kw": 500.0,
            "total_heat_area_m2": 125.0
        }
        
        db.finalize_session(summary_stats)
        print(f"   âœ… Session finalized with I-N column support")
        
        # 6. æµ‹è¯•æ•°æ®åº“æ‘˜è¦
        print("\n5ï¸âƒ£ Database Summary:")
        summary = db.get_database_summary()
        print(f"   ğŸ“Š Database Status: {summary['status']}")
        print(f"   ğŸ“ Database Path: {summary['database_path']}")
        print(f"   ğŸ”¢ Total Records: {summary['total_records']}")
        print(f"   ğŸ“‹ I-N Column Coverage: {summary.get('i_to_n_column_coverage', {})}")
        
        print("\n" + "="*60)
        print("âœ… DATABASE SYSTEM TEST COMPLETED SUCCESSFULLY - I-N Enhanced")
        print("="*60)
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Database test failed: {e}")
        import traceback
        traceback.print_exc()
        return False
        
    finally:
        db.close()


if __name__ == "__main__":
    test_database_system()