#!/usr/bin/env python3
"""
I-N Column Data Fix Script V2

ä¿®å¤ç‰ˆæœ¬ï¼šå…ˆä¿®å¤æ•°æ®åº“è¡¨ç»“æ„ï¼Œå†å¡«å……I-Nåˆ—æ•°æ®
ä¸“é—¨è§£å†³BFG-CO2H-HEX.xlsxä¸­I-Nåˆ—æ•°æ®æå–å’Œå­˜å‚¨é—®é¢˜

Author: TEA Analysis Framework  
Date: 2025-07-26
Version: 2.0 - Complete Fix with Schema Update
"""

import pandas as pd
import sqlite3
import json
import logging
import os
from datetime import datetime
from typing import Dict, List, Any, Optional

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')
logger = logging.getLogger(__name__)

class IToNColumnFixerV2:
    """
    ä¸“é—¨ç”¨äºä¿®å¤I-Nåˆ—æ•°æ®æå–é—®é¢˜çš„ç±»ï¼ˆV2ç‰ˆæœ¬ï¼‰
    åŒ…å«è¡¨ç»“æ„ä¿®å¤å’Œæ•°æ®å¡«å……
    """
    
    def __init__(self, excel_file: str = "BFG-CO2H-HEX.xlsx", db_path: str = "aspen_data.db"):
        self.excel_file = excel_file
        self.db_path = db_path
        self.df = None
        self.i_to_n_data = {}
        
    def complete_fix(self) -> Dict[str, Any]:
        """
        å®Œæ•´ä¿®å¤æµç¨‹ï¼šè¡¨ç»“æ„ä¿®å¤ + æ•°æ®å¡«å……
        """
        print("\n" + "="*80)
        print("ğŸ”§ I-Nåˆ—æ•°æ®å®Œæ•´ä¿®å¤å·¥å…· V2")
        print("="*80)
        print(f"Excelæ–‡ä»¶: {self.excel_file}")
        print(f"æ•°æ®åº“: {self.db_path}")
        print(f"ä¿®å¤æ—¶é—´: {datetime.now().isoformat()}")
        
        results = {
            'step_1_schema_fix': self._step1_fix_database_schema(),
            'step_2_excel_analysis': self._step2_analyze_excel(),
            'step_3_extract_i_to_n': self._step3_extract_i_to_n_data(),
            'step_4_update_database': self._step4_update_database(),
            'step_5_verify_fix': self._step5_verify_fix()
        }
        
        self._generate_complete_report(results)
        return results
    
    def _step1_fix_database_schema(self) -> Dict[str, Any]:
        """
        Step 1: ä¿®å¤æ•°æ®åº“è¡¨ç»“æ„ï¼Œç¡®ä¿I-Nåˆ—å­—æ®µå­˜åœ¨
        """
        print("\nğŸ”§ Step 1: ä¿®å¤æ•°æ®åº“è¡¨ç»“æ„")
        print("-" * 50)
        
        result = {
            'success': False,
            'database_exists': False,
            'table_exists': False,
            'columns_added': [],
            'error': None
        }
        
        try:
            # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶
            if not os.path.exists(self.db_path):
                print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {self.db_path}")
                return result
            
            result['database_exists'] = True
            print(f"âœ… æ•°æ®åº“æ–‡ä»¶å­˜åœ¨: {self.db_path}")
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ£€æŸ¥heat_exchangersè¡¨
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='heat_exchangers'")
            if not cursor.fetchone():
                print("ğŸ“‹ heat_exchangersè¡¨ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®Œæ•´è¡¨ç»“æ„")
                self._create_complete_heat_exchangers_table(cursor)
                result['table_exists'] = True
            else:
                result['table_exists'] = True
                print("âœ… heat_exchangersè¡¨å­˜åœ¨")
            
            # è·å–ç°æœ‰å­—æ®µ
            cursor.execute("PRAGMA table_info(heat_exchangers)")
            existing_columns = [col[1] for col in cursor.fetchall()]
            
            # éœ€è¦çš„I-Nåˆ—å­—æ®µ
            required_i_to_n_fields = [
                ('column_i_data', 'REAL'),
                ('column_i_header', 'TEXT'),
                ('column_j_data', 'REAL'), 
                ('column_j_header', 'TEXT'),
                ('column_k_data', 'REAL'),
                ('column_k_header', 'TEXT'),
                ('column_l_data', 'REAL'),
                ('column_l_header', 'TEXT'),
                ('column_m_data', 'REAL'),
                ('column_m_header', 'TEXT'),
                ('column_n_data', 'REAL'),
                ('column_n_header', 'TEXT'),
                ('columns_i_to_n_raw', 'TEXT')
            ]
            
            # æ·»åŠ ç¼ºå¤±å­—æ®µ
            columns_added = 0
            for col_name, col_type in required_i_to_n_fields:
                if col_name not in existing_columns:
                    try:
                        cursor.execute(f"ALTER TABLE heat_exchangers ADD COLUMN {col_name} {col_type}")
                        result['columns_added'].append(col_name)
                        columns_added += 1
                        print(f"   âœ… æ·»åŠ å­—æ®µ: {col_name}")
                    except Exception as e:
                        print(f"   âŒ æ·»åŠ å­—æ®µå¤±è´¥ {col_name}: {e}")
            
            conn.commit()
            conn.close()
            
            if columns_added > 0 or len([col for col in existing_columns if 'column_' in col and ('_data' in col or '_header' in col)]) >= 10:
                result['success'] = True
                print(f"âœ… è¡¨ç»“æ„ä¿®å¤æˆåŠŸï¼Œæ·»åŠ äº† {columns_added} ä¸ªå­—æ®µ")
            else:
                print(f"âš ï¸ è¡¨ç»“æ„å¯èƒ½å·²ç»å®Œæ•´")
                result['success'] = True  # å­—æ®µå·²å­˜åœ¨ä¹Ÿç®—æˆåŠŸ
            
        except Exception as e:
            print(f"âŒ è¡¨ç»“æ„ä¿®å¤å¤±è´¥: {e}")
            result['error'] = str(e)
        
        return result
    
    def _create_complete_heat_exchangers_table(self, cursor):
        """åˆ›å»ºå®Œæ•´çš„heat_exchangersè¡¨"""
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS heat_exchangers (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT NOT NULL,
                name TEXT NOT NULL,
                duty_kw REAL DEFAULT 0.0,
                area_m2 REAL DEFAULT 0.0,
                temperatures TEXT,
                pressures TEXT,
                source TEXT DEFAULT 'unknown',
                extraction_time TEXT,
                hot_stream_name TEXT,
                hot_stream_inlet_temp REAL,
                hot_stream_outlet_temp REAL,
                hot_stream_flow_rate REAL,
                hot_stream_composition TEXT,
                cold_stream_name TEXT,
                cold_stream_inlet_temp REAL,
                cold_stream_outlet_temp REAL,
                cold_stream_flow_rate REAL,
                cold_stream_composition TEXT,
                column_i_data REAL,
                column_i_header TEXT,
                column_j_data REAL,
                column_j_header TEXT,
                column_k_data REAL,
                column_k_header TEXT,
                column_l_data REAL,
                column_l_header TEXT,
                column_m_data REAL,
                column_m_header TEXT,
                column_n_data REAL,
                column_n_header TEXT,
                columns_i_to_n_raw TEXT
            )
        """)
    
    def _step2_analyze_excel(self) -> Dict[str, Any]:
        """
        Step 2: åˆ†æExcelæ–‡ä»¶
        """
        print(f"\nğŸ” Step 2: åˆ†æExcelæ–‡ä»¶")
        print("-" * 50)
        
        result = {
            'success': False,
            'file_found': False,
            'total_columns': 0,
            'total_rows': 0,
            'i_to_n_columns': {},
            'error': None
        }
        
        try:
            if not os.path.exists(self.excel_file):
                print(f"âŒ Excelæ–‡ä»¶ä¸å­˜åœ¨: {self.excel_file}")
                return result
            
            result['file_found'] = True
            print(f"âœ… Excelæ–‡ä»¶æ‰¾åˆ°: {self.excel_file}")
            
            # è¯»å–Excel
            self.df = pd.read_excel(self.excel_file)
            result['total_columns'] = len(self.df.columns)
            result['total_rows'] = len(self.df)
            
            print(f"ğŸ“Š æ–‡ä»¶ç»“æ„: {result['total_rows']} è¡Œ Ã— {result['total_columns']} åˆ—")
            
            # I-Nåˆ—æ˜ å°„ï¼ˆç´¢å¼•8-13ï¼‰
            i_to_n_mapping = {'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13}
            
            for excel_col, col_idx in i_to_n_mapping.items():
                if col_idx < len(self.df.columns):
                    header = str(self.df.columns[col_idx])
                    non_null_count = self.df.iloc[:, col_idx].notna().sum()
                    result['i_to_n_columns'][excel_col] = {
                        'index': col_idx,
                        'header': header,
                        'non_null_count': int(non_null_count)
                    }
                    print(f"   åˆ—{excel_col}: '{header}' ({non_null_count} ä¸ªæœ‰æ•ˆå€¼)")
            
            result['success'] = True
            
        except Exception as e:
            print(f"âŒ Excelåˆ†æå¤±è´¥: {e}")
            result['error'] = str(e)
        
        return result
    
    def _step3_extract_i_to_n_data(self) -> Dict[str, Any]:
        """
        Step 3: æå–I-Nåˆ—æ•°æ®
        """
        print(f"\nğŸ“¤ Step 3: æå–I-Nåˆ—æ•°æ®")
        print("-" * 50)
        
        result = {
            'success': False,
            'total_rows_processed': 0,
            'rows_with_i_to_n_data': 0,
            'extracted_data_count': {},
            'error': None
        }
        
        try:
            if self.df is None:
                print("âŒ Excelæ•°æ®æœªåŠ è½½")
                return result
            
            i_to_n_mapping = {'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13}
            extracted_data = []
            rows_with_data = 0
            
            for idx, row in self.df.iterrows():
                row_data = {
                    'row_index': idx,
                    'name': f'HEX-{idx+1:03d}',
                    'i_to_n_columns': {}
                }
                
                has_data = False
                for excel_col, col_idx in i_to_n_mapping.items():
                    if col_idx < len(self.df.columns):
                        header = str(self.df.columns[col_idx])
                        value = row.iloc[col_idx] if col_idx < len(row) else None
                        
                        # å¯¹äºæ•°å€¼åˆ—ï¼Œè½¬æ¢ä¸ºfloatï¼›å¯¹äºæ–‡æœ¬åˆ—ï¼Œä¿æŒå­—ç¬¦ä¸²
                        if excel_col in ['I', 'L']:  # æµè‚¡åç§°åˆ—
                            clean_value = str(value) if value is not None and not pd.isna(value) else None
                        else:  # æ¸©åº¦åˆ—
                            clean_value = self._clean_numeric_value(value)
                        
                        if clean_value is not None:
                            row_data['i_to_n_columns'][excel_col.lower()] = {
                                'data': clean_value,
                                'header': header,
                                'raw_value': value
                            }
                            has_data = True
                
                if has_data:
                    extracted_data.append(row_data)
                    rows_with_data += 1
            
            self.i_to_n_data = extracted_data
            result['total_rows_processed'] = len(self.df)
            result['rows_with_i_to_n_data'] = rows_with_data
            
            # ç»Ÿè®¡æ¯åˆ—
            for excel_col in ['I', 'J', 'K', 'L', 'M', 'N']:
                count = sum(1 for row in extracted_data if excel_col.lower() in row['i_to_n_columns'])
                result['extracted_data_count'][excel_col] = count
            
            if rows_with_data > 0:
                result['success'] = True
                print(f"âœ… æ•°æ®æå–æˆåŠŸ: {rows_with_data} è¡Œï¼Œå„åˆ—æƒ…å†µï¼š")
                for col, count in result['extracted_data_count'].items():
                    print(f"   åˆ—{col}: {count} ä¸ªå€¼")
            
        except Exception as e:
            print(f"âŒ æ•°æ®æå–å¤±è´¥: {e}")
            result['error'] = str(e)
        
        return result
    
    def _step4_update_database(self) -> Dict[str, Any]:
        """
        Step 4: æ›´æ–°æ•°æ®åº“
        """
        print(f"\nğŸ’¾ Step 4: æ›´æ–°æ•°æ®åº“")
        print("-" * 50)
        
        result = {
            'success': False,
            'records_updated': 0,
            'error': None
        }
        
        try:
            if not self.i_to_n_data:
                print("âŒ æ²¡æœ‰æå–åˆ°æ•°æ®")
                return result
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # è·å–æˆ–åˆ›å»ºä¼šè¯ID
            cursor.execute("SELECT session_id FROM extraction_sessions ORDER BY extraction_time DESC LIMIT 1")
            session_result = cursor.fetchone()
            session_id = session_result[0] if session_result else f"fix_session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            # æ¸…ç©ºå¹¶é‡æ–°æ’å…¥æ•°æ®
            cursor.execute("DELETE FROM heat_exchangers")
            extraction_time = datetime.now().isoformat()
            
            for row_data in self.i_to_n_data:
                i_to_n_cols = row_data['i_to_n_columns']
                
                # å‡†å¤‡I-Nåˆ—æ•°æ®
                i_data = i_to_n_cols.get('i', {})
                j_data = i_to_n_cols.get('j', {})
                k_data = i_to_n_cols.get('k', {})
                l_data = i_to_n_cols.get('l', {})
                m_data = i_to_n_cols.get('m', {})
                n_data = i_to_n_cols.get('n', {})
                
                # åŸå§‹æ•°æ®
                raw_data = {col_name.upper(): col_info.get('data') for col_name, col_info in i_to_n_cols.items()}
                
                cursor.execute("""
                    INSERT INTO heat_exchangers (
                        session_id, name, duty_kw, area_m2, temperatures, pressures,
                        source, extraction_time,
                        column_i_data, column_i_header,
                        column_j_data, column_j_header,
                        column_k_data, column_k_header,
                        column_l_data, column_l_header,
                        column_m_data, column_m_header,
                        column_n_data, column_n_header,
                        columns_i_to_n_raw
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    session_id, row_data['name'], 0.0, 0.0, 
                    json.dumps({}), json.dumps({}), 'excel_fix_v2', extraction_time,
                    i_data.get('data'), i_data.get('header'),
                    j_data.get('data'), j_data.get('header'),
                    k_data.get('data'), k_data.get('header'),
                    l_data.get('data'), l_data.get('header'),
                    m_data.get('data'), m_data.get('header'),
                    n_data.get('data'), n_data.get('header'),
                    json.dumps(raw_data) if raw_data else None
                ))
            
            conn.commit()
            result['records_updated'] = len(self.i_to_n_data)
            result['success'] = True
            
            print(f"âœ… æ•°æ®åº“æ›´æ–°æˆåŠŸ: {result['records_updated']} æ¡è®°å½•")
            conn.close()
            
        except Exception as e:
            print(f"âŒ æ•°æ®åº“æ›´æ–°å¤±è´¥: {e}")
            result['error'] = str(e)
            import traceback
            traceback.print_exc()
        
        return result
    
    def _step5_verify_fix(self) -> Dict[str, Any]:
        """
        Step 5: éªŒè¯ä¿®å¤ç»“æœ
        """
        print(f"\nâœ… Step 5: éªŒè¯ä¿®å¤ç»“æœ")
        print("-" * 50)
        
        result = {
            'success': False,
            'total_records': 0,
            'i_to_n_coverage': {},
            'sample_data': [],
            'error': None
        }
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ£€æŸ¥è®°å½•æ•°
            cursor.execute("SELECT COUNT(*) FROM heat_exchangers")
            result['total_records'] = cursor.fetchone()[0]
            print(f"ğŸ“Š æ€»è®°å½•æ•°: {result['total_records']}")
            
            # æ£€æŸ¥I-Nåˆ—è¦†ç›–ç‡
            i_to_n_columns = [
                ('column_i_data', 'I'), ('column_j_data', 'J'), ('column_k_data', 'K'),
                ('column_l_data', 'L'), ('column_m_data', 'M'), ('column_n_data', 'N')
            ]
            
            total_values = 0
            for db_col, excel_col in i_to_n_columns:
                cursor.execute(f"SELECT COUNT(*) FROM heat_exchangers WHERE {db_col} IS NOT NULL")
                count = cursor.fetchone()[0]
                coverage = (count / result['total_records']) * 100 if result['total_records'] > 0 else 0
                result['i_to_n_coverage'][excel_col] = {'count': count, 'coverage': coverage}
                total_values += count
                print(f"   åˆ—{excel_col}: {count}/{result['total_records']} ({coverage:.1f}%)")
            
            # æ ·æœ¬æ•°æ®
            cursor.execute("""
                SELECT name, column_i_data, column_j_data, column_k_data,
                       column_l_data, column_m_data, column_n_data
                FROM heat_exchangers LIMIT 3
            """)
            
            for row in cursor.fetchall():
                result['sample_data'].append({
                    'name': row[0],
                    'values': {'I': row[1], 'J': row[2], 'K': row[3], 'L': row[4], 'M': row[5], 'N': row[6]}
                })
            
            print(f"ğŸ”¬ æ ·æœ¬æ•°æ®:")
            for sample in result['sample_data']:
                print(f"   {sample['name']}: {sample['values']}")
            
            if total_values > 0:
                result['success'] = True
                print(f"âœ… éªŒè¯æˆåŠŸ! æ€»è®¡ {total_values} ä¸ªI-Næ•°æ®ç‚¹")
            
            conn.close()
            
        except Exception as e:
            print(f"âŒ éªŒè¯å¤±è´¥: {e}")
            result['error'] = str(e)
        
        return result
    
    def _clean_numeric_value(self, value) -> Optional[float]:
        """æ¸…ç†æ•°å€¼æ•°æ®"""
        if value is None or pd.isna(value):
            return None
        
        if isinstance(value, (int, float)):
            return float(value)
        
        if isinstance(value, str):
            import re
            clean_str = re.sub(r'[^\d.-]', '', str(value).strip())
            if clean_str:
                try:
                    return float(clean_str)
                except ValueError:
                    pass
        
        return None
    
    def _generate_complete_report(self, results: Dict[str, Any]) -> None:
        """ç”Ÿæˆå®Œæ•´æŠ¥å‘Š"""
        print(f"\nğŸ“‹ I-Nåˆ—å®Œæ•´ä¿®å¤æŠ¥å‘Š")
        print("=" * 80)
        
        steps_passed = sum(1 for result in results.values() if result.get('success', False))
        total_steps = len(results)
        
        print(f"ä¿®å¤çŠ¶æ€: {steps_passed}/{total_steps} æ­¥éª¤æˆåŠŸ")
        
        if steps_passed == total_steps:
            print("ğŸ‰ I-Nåˆ—æ•°æ®å®Œæ•´ä¿®å¤æˆåŠŸ!")
            
            verify_result = results.get('step_5_verify_fix', {})
            if verify_result.get('success'):
                coverage = verify_result.get('i_to_n_coverage', {})
                total_values = sum(col_info.get('count', 0) for col_info in coverage.values())
                print(f"ğŸ“Š ä¿®å¤æˆæœ: {verify_result.get('total_records', 0)} æ¡è®°å½•ï¼Œ{total_values} ä¸ªI-Næ•°æ®ç‚¹")
        else:
            print("âš ï¸ éƒ¨åˆ†æ­¥éª¤å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = f"i_to_n_complete_fix_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)
            print(f"ğŸ’¾ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        except Exception as e:
            print(f"âŒ æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨I-Nåˆ—æ•°æ®å®Œæ•´ä¿®å¤å·¥å…· V2")
    
    fixer = IToNColumnFixerV2()
    results = fixer.complete_fix()
    
    success = all(result.get('success', False) for result in results.values())
    
    if success:
        print(f"\nğŸ‰ I-Nåˆ—æ•°æ®å®Œæ•´ä¿®å¤æˆåŠŸ!")
        print("æ•°æ®åº“ä¸­çš„heat_exchangersè¡¨ç°åœ¨åŒ…å«å®Œæ•´çš„I-Nåˆ—æ•°æ®")
    else:
        print(f"\nâš ï¸ ä¿®å¤æœªå®Œå…¨æˆåŠŸï¼Œè¯·æŸ¥çœ‹æŠ¥å‘Šæ–‡ä»¶")
    
    return success


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)