#!/usr/bin/env python3
"""
æµè‚¡æ˜ å°„æŸ¥è¯¢å·¥å…·

ç”¨äºæŸ¥è¯¢å’Œä½¿ç”¨æ•°æ®åº“ä¸­çš„æµè‚¡åç§°æ˜ å°„å…³ç³»
"""

import sqlite3
import pandas as pd
from typing import Dict, List, Optional, Tuple
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class StreamMappingQuery:
    """æµè‚¡æ˜ å°„æŸ¥è¯¢å™¨"""
    
    def __init__(self, db_path: str = "aspen_data.db"):
        self.db_path = db_path
    
    def get_all_mappings(self, table_name: str = "improved_stream_mappings") -> List[Tuple]:
        """è·å–æ‰€æœ‰æ˜ å°„å…³ç³»"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute(f"""
                SELECT database_name, aspen_name, confidence, explanation, mapping_type 
                FROM {table_name}
                ORDER BY confidence DESC, database_name
            """)
            
            mappings = cursor.fetchall()
            conn.close()
            
            return mappings
            
        except Exception as e:
            logger.error(f"æŸ¥è¯¢æ˜ å°„æ—¶å‡ºé”™: {e}")
            return []
    
    def get_mapping_by_db_name(self, db_name: str, table_name: str = "improved_stream_mappings") -> Optional[Tuple]:
        """æ ¹æ®æ•°æ®åº“åç§°æŸ¥è¯¢æ˜ å°„"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute(f"""
                SELECT database_name, aspen_name, confidence, explanation 
                FROM {table_name}
                WHERE database_name = ?
            """, (db_name,))
            
            result = cursor.fetchone()
            conn.close()
            
            return result
            
        except Exception as e:
            logger.error(f"æŸ¥è¯¢æ˜ å°„æ—¶å‡ºé”™: {e}")
            return None
    
    def get_mapping_by_aspen_name(self, aspen_name: str, table_name: str = "improved_stream_mappings") -> List[Tuple]:
        """æ ¹æ®Aspenåç§°æŸ¥è¯¢æ˜ å°„ï¼ˆå¯èƒ½æœ‰å¤šä¸ªæ•°æ®åº“åç§°å¯¹åº”åŒä¸€ä¸ªAspenåç§°ï¼‰"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute(f"""
                SELECT database_name, aspen_name, confidence, explanation 
                FROM {table_name}
                WHERE aspen_name = ?
                ORDER BY confidence DESC
            """, (aspen_name,))
            
            results = cursor.fetchall()
            conn.close()
            
            return results
            
        except Exception as e:
            logger.error(f"æŸ¥è¯¢æ˜ å°„æ—¶å‡ºé”™: {e}")
            return []
    
    def get_mapping_dict(self, min_confidence: float = 0.0, table_name: str = "improved_stream_mappings") -> Dict[str, str]:
        """è·å–æ˜ å°„å­—å…¸ (æ•°æ®åº“å -> Aspenå)"""
        mappings = {}
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute(f"""
                SELECT database_name, aspen_name, confidence 
                FROM {table_name}
                WHERE confidence >= ?
                ORDER BY database_name
            """, (min_confidence,))
            
            for db_name, aspen_name, confidence in cursor.fetchall():
                mappings[db_name] = aspen_name
            
            conn.close()
            
        except Exception as e:
            logger.error(f"è·å–æ˜ å°„å­—å…¸æ—¶å‡ºé”™: {e}")
        
        return mappings
    
    def get_reverse_mapping_dict(self, min_confidence: float = 0.0, table_name: str = "improved_stream_mappings") -> Dict[str, List[str]]:
        """è·å–åå‘æ˜ å°„å­—å…¸ (Aspenå -> [æ•°æ®åº“ååˆ—è¡¨])"""
        mappings = {}
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute(f"""
                SELECT database_name, aspen_name, confidence 
                FROM {table_name}
                WHERE confidence >= ?
                ORDER BY aspen_name, confidence DESC
            """, (min_confidence,))
            
            for db_name, aspen_name, confidence in cursor.fetchall():
                if aspen_name not in mappings:
                    mappings[aspen_name] = []
                mappings[aspen_name].append(db_name)
            
            conn.close()
            
        except Exception as e:
            logger.error(f"è·å–åå‘æ˜ å°„å­—å…¸æ—¶å‡ºé”™: {e}")
        
        return mappings
    
    def export_to_excel(self, filename: str = None, table_name: str = "improved_stream_mappings") -> bool:
        """å¯¼å‡ºæ˜ å°„åˆ°Excelæ–‡ä»¶"""
        if filename is None:
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"stream_mappings_{timestamp}.xlsx"
        
        try:
            conn = sqlite3.connect(self.db_path)
            
            # æŸ¥è¯¢æ˜ å°„æ•°æ®
            df = pd.read_sql_query(f"""
                SELECT 
                    database_name as 'æ•°æ®åº“æµè‚¡å',
                    aspen_name as 'Aspenæµè‚¡å',
                    confidence as 'ç½®ä¿¡åº¦',
                    explanation as 'æ˜ å°„è¯´æ˜',
                    mapping_type as 'æ˜ å°„ç±»å‹',
                    created_at as 'åˆ›å»ºæ—¶é—´'
                FROM {table_name}
                ORDER BY confidence DESC, database_name
            """, conn)
            
            conn.close()
            
            # ä¿å­˜åˆ°Excel
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name='æµè‚¡æ˜ å°„', index=False)
                
                # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                stats_data = {
                    'ç»Ÿè®¡é¡¹ç›®': ['æ€»æ˜ å°„æ•°', 'é«˜ç½®ä¿¡åº¦(â‰¥0.85)', 'ä¸­ç­‰ç½®ä¿¡åº¦(0.75-0.84)', 'ä½ç½®ä¿¡åº¦(<0.75)'],
                    'æ•°é‡': [
                        len(df),
                        len(df[df['ç½®ä¿¡åº¦'] >= 0.85]),
                        len(df[(df['ç½®ä¿¡åº¦'] >= 0.75) & (df['ç½®ä¿¡åº¦'] < 0.85)]),
                        len(df[df['ç½®ä¿¡åº¦'] < 0.75])
                    ]
                }
                stats_df = pd.DataFrame(stats_data)
                stats_df.to_excel(writer, sheet_name='ç»Ÿè®¡ä¿¡æ¯', index=False)
            
            logger.info(f"âœ… æ˜ å°„æ•°æ®å·²å¯¼å‡ºåˆ°: {filename}")
            return True
            
        except Exception as e:
            logger.error(f"å¯¼å‡ºExcelæ—¶å‡ºé”™: {e}")
            return False
    
    def print_mapping_summary(self, table_name: str = "improved_stream_mappings"):
        """æ‰“å°æ˜ å°„æ‘˜è¦"""
        mappings = self.get_all_mappings(table_name)
        
        if not mappings:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ˜ å°„æ•°æ®")
            return
        
        print("\n" + "="*80)
        print(f"ğŸ“‹ æµè‚¡æ˜ å°„æ‘˜è¦ (è¡¨: {table_name})")
        print("="*80)
        
        # æŒ‰ç½®ä¿¡åº¦åˆ†ç»„
        high_conf = [m for m in mappings if m[2] >= 0.85]
        medium_conf = [m for m in mappings if 0.75 <= m[2] < 0.85]
        low_conf = [m for m in mappings if m[2] < 0.75]
        
        print(f"\nğŸ“Š æ˜ å°„ç»Ÿè®¡:")
        print(f"  â€¢ æ€»æ˜ å°„æ•°: {len(mappings)}")
        print(f"  â€¢ é«˜ç½®ä¿¡åº¦ (â‰¥0.85): {len(high_conf)} ({len(high_conf)/len(mappings)*100:.1f}%)")
        print(f"  â€¢ ä¸­ç­‰ç½®ä¿¡åº¦ (0.75-0.84): {len(medium_conf)} ({len(medium_conf)/len(mappings)*100:.1f}%)")
        print(f"  â€¢ ä½ç½®ä¿¡åº¦ (<0.75): {len(low_conf)} ({len(low_conf)/len(mappings)*100:.1f}%)")
        
        print(f"\nğŸŸ¢ é«˜ç½®ä¿¡åº¦æ˜ å°„ ({len(high_conf)} ä¸ª):")
        print("-" * 70)
        for db_name, aspen_name, confidence, explanation, _ in high_conf:
            print(f"  {db_name:25} â†’ {aspen_name:15} ({confidence:.2f})")
        
        if medium_conf:
            print(f"\nğŸŸ¡ ä¸­ç­‰ç½®ä¿¡åº¦æ˜ å°„ ({len(medium_conf)} ä¸ª):")
            print("-" * 70)
            for db_name, aspen_name, confidence, explanation, _ in medium_conf:
                print(f"  {db_name:25} â†’ {aspen_name:15} ({confidence:.2f})")
        
        if low_conf:
            print(f"\nğŸ”´ ä½ç½®ä¿¡åº¦æ˜ å°„ ({len(low_conf)} ä¸ª):")
            print("-" * 70)
            for db_name, aspen_name, confidence, explanation, _ in low_conf:
                print(f"  {db_name:25} â†’ {aspen_name:15} ({confidence:.2f})")
    
    def search_mapping(self, keyword: str, table_name: str = "improved_stream_mappings") -> List[Tuple]:
        """æœç´¢åŒ…å«å…³é”®è¯çš„æ˜ å°„"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute(f"""
                SELECT database_name, aspen_name, confidence, explanation 
                FROM {table_name}
                WHERE database_name LIKE ? OR aspen_name LIKE ? OR explanation LIKE ?
                ORDER BY confidence DESC
            """, (f'%{keyword}%', f'%{keyword}%', f'%{keyword}%'))
            
            results = cursor.fetchall()
            conn.close()
            
            return results
            
        except Exception as e:
            logger.error(f"æœç´¢æ˜ å°„æ—¶å‡ºé”™: {e}")
            return []

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºæŸ¥è¯¢åŠŸèƒ½"""
    print("ğŸ” æµè‚¡æ˜ å°„æŸ¥è¯¢å·¥å…·")
    print("="*50)
    
    query = StreamMappingQuery()
    
    # æ˜¾ç¤ºæ˜ å°„æ‘˜è¦
    query.print_mapping_summary()
    
    # è·å–é«˜ç½®ä¿¡åº¦æ˜ å°„å­—å…¸
    print("\n" + "="*50)
    print("ğŸ“– é«˜ç½®ä¿¡åº¦æ˜ å°„å­—å…¸ (ç½®ä¿¡åº¦ â‰¥ 0.85):")
    print("="*50)
    high_conf_dict = query.get_mapping_dict(min_confidence=0.85)
    for db_name, aspen_name in high_conf_dict.items():
        print(f"  '{db_name}' â†’ '{aspen_name}'")
    
    # å±•ç¤ºä¸€äº›æŸ¥è¯¢ç¤ºä¾‹
    print("\n" + "="*50)
    print("ğŸ” æŸ¥è¯¢ç¤ºä¾‹:")
    print("="*50)
    
    # æŸ¥è¯¢ç‰¹å®šçš„æ•°æ®åº“æµè‚¡
    test_db_name = "BFG-FEED"
    result = query.get_mapping_by_db_name(test_db_name)
    if result:
        print(f"âœ… æŸ¥è¯¢ '{test_db_name}': {result[0]} â†’ {result[1]} (ç½®ä¿¡åº¦: {result[2]:.2f})")
    
    # æœç´¢ç”²é†‡ç›¸å…³æ˜ å°„
    methanol_results = query.search_mapping("ç”²é†‡")
    if methanol_results:
        print(f"âœ… æœç´¢ 'ç”²é†‡' ç›¸å…³æ˜ å°„:")
        for db_name, aspen_name, confidence, explanation in methanol_results:
            print(f"    {db_name} â†’ {aspen_name} ({confidence:.2f}) - {explanation}")
    
    # å¯¼å‡ºExcel
    print("\nğŸ’¾ å¯¼å‡ºæ˜ å°„åˆ°Excel...")
    if query.export_to_excel():
        print("âœ… Excelå¯¼å‡ºæˆåŠŸ")
    else:
        print("âŒ Excelå¯¼å‡ºå¤±è´¥")

if __name__ == "__main__":
    main()
