#!/usr/bin/env python3
"""
è¯»å–aspen_flowsheet.xlsxæ–‡ä»¶ï¼Œåˆ†æè®¾å¤‡å’Œæµè‚¡çš„é“¾æ¥ä¿¡æ¯

Author: æ•°æ®åˆ†æå·¥å…·
Date: 2025-07-27
"""

import pandas as pd
import logging
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def read_flowsheet_excel(file_path: str):
    """
    è¯»å–flowsheet Excelæ–‡ä»¶å¹¶åˆ†æç»“æ„
    
    Args:
        file_path: Excelæ–‡ä»¶è·¯å¾„
    """
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not Path(file_path).exists():
            logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return
        
        logger.info(f"ğŸ“– æ­£åœ¨è¯»å–æ–‡ä»¶: {file_path}")
        
        # è¯»å–Excelæ–‡ä»¶çš„æ‰€æœ‰å·¥ä½œè¡¨
        excel_file = pd.ExcelFile(file_path)
        logger.info(f"å‘ç° {len(excel_file.sheet_names)} ä¸ªå·¥ä½œè¡¨: {excel_file.sheet_names}")
        
        # åˆ†ææ¯ä¸ªå·¥ä½œè¡¨
        all_data = {}
        for sheet_name in excel_file.sheet_names:
            logger.info(f"\nğŸ” åˆ†æå·¥ä½œè¡¨: {sheet_name}")
            
            try:
                # è¯»å–å·¥ä½œè¡¨
                df = pd.read_excel(file_path, sheet_name=sheet_name)
                all_data[sheet_name] = df
                
                logger.info(f"  ğŸ“Š æ•°æ®ç»´åº¦: {df.shape} (è¡Œxåˆ—)")
                
                if not df.empty:
                    logger.info(f"  ğŸ“‹ åˆ—å: {list(df.columns)}")
                    
                    # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
                    logger.info("  ğŸ“ å‰5è¡Œæ•°æ®:")
                    print(df.head().to_string())
                    
                    # åˆ†ææ•°æ®ç±»å‹
                    logger.info("  ğŸ”¢ æ•°æ®ç±»å‹:")
                    for col in df.columns:
                        non_null_count = df[col].count()
                        total_count = len(df)
                        logger.info(f"    {col}: {df[col].dtype} ({non_null_count}/{total_count} éç©º)")
                    
                    # å¦‚æœæœ‰è®¾å¤‡å’Œæµè‚¡ç›¸å…³çš„åˆ—ï¼Œè¿›è¡Œç‰¹æ®Šåˆ†æ
                    analyze_equipment_stream_connections(df, sheet_name)
                    
            except Exception as e:
                logger.error(f"  âŒ è¯»å–å·¥ä½œè¡¨ {sheet_name} æ—¶å‡ºé”™: {str(e)}")
        
        return all_data
        
    except Exception as e:
        logger.error(f"âŒ è¯»å–Excelæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return None

def analyze_equipment_stream_connections(df, sheet_name):
    """
    åˆ†æè®¾å¤‡å’Œæµè‚¡è¿æ¥ä¿¡æ¯
    
    Args:
        df: DataFrame
        sheet_name: å·¥ä½œè¡¨åç§°
    """
    logger.info(f"\nğŸ”— åˆ†æ {sheet_name} ä¸­çš„è®¾å¤‡æµè‚¡è¿æ¥:")
    
    # æŸ¥æ‰¾å¯èƒ½åŒ…å«è®¾å¤‡ä¿¡æ¯çš„åˆ—
    equipment_cols = [col for col in df.columns if any(keyword in col.lower() 
                     for keyword in ['equipment', 'block', 'unit', 'è®¾å¤‡', 'å—'])]
    
    # æŸ¥æ‰¾å¯èƒ½åŒ…å«æµè‚¡ä¿¡æ¯çš„åˆ—
    stream_cols = [col for col in df.columns if any(keyword in col.lower() 
                  for keyword in ['stream', 'flow', 'inlet', 'outlet', 'æµè‚¡', 'è¿›æ–™', 'å‡ºæ–™', 'feed', 'product'])]
    
    # æŸ¥æ‰¾å¯èƒ½åŒ…å«è¿æ¥ä¿¡æ¯çš„åˆ—
    connection_cols = [col for col in df.columns if any(keyword in col.lower() 
                      for keyword in ['from', 'to', 'source', 'destination', 'æ¥æº', 'ç›®æ ‡', 'connect'])]
    
    if equipment_cols:
        logger.info(f"  ğŸ­ è®¾å¤‡ç›¸å…³åˆ—: {equipment_cols}")
        
    if stream_cols:
        logger.info(f"  ğŸŒŠ æµè‚¡ç›¸å…³åˆ—: {stream_cols}")
        
    if connection_cols:
        logger.info(f"  ğŸ”— è¿æ¥ç›¸å…³åˆ—: {connection_cols}")
    
    # åˆ†æå”¯ä¸€å€¼
    for col in df.columns:
        if df[col].dtype == 'object':  # æ–‡æœ¬åˆ—
            unique_values = df[col].dropna().unique()
            if len(unique_values) <= 20:  # åªæ˜¾ç¤ºä¸è¶…è¿‡20ä¸ªå”¯ä¸€å€¼
                logger.info(f"  ğŸ“‹ '{col}' çš„å”¯ä¸€å€¼: {list(unique_values)}")
            else:
                logger.info(f"  ğŸ“‹ '{col}' æœ‰ {len(unique_values)} ä¸ªå”¯ä¸€å€¼")
                logger.info(f"      å‰10ä¸ªå€¼: {list(unique_values[:10])}")
    
    # å°è¯•è¯†åˆ«è¿æ¥æ¨¡å¼
    identify_connection_patterns(df, sheet_name)

def identify_connection_patterns(df, sheet_name):
    """
    è¯†åˆ«è¿æ¥æ¨¡å¼å’Œå…³ç³»
    
    Args:
        df: DataFrame
        sheet_name: å·¥ä½œè¡¨åç§°
    """
    logger.info(f"\nğŸ“Š è¯†åˆ« {sheet_name} ä¸­çš„è¿æ¥æ¨¡å¼:")
    
    # æŸ¥æ‰¾åŒ…å«ç®­å¤´æˆ–è¿æ¥ç¬¦çš„åˆ—
    for col in df.columns:
        if df[col].dtype == 'object':
            sample_values = df[col].dropna().head(10).tolist()
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å¸¸è§çš„è¿æ¥ç¬¦å·
            connection_indicators = ['â†’', '->', '-->', '==>', '|', 'æµå‘', 'åˆ°', 'to', 'from']
            
            for value in sample_values:
                if isinstance(value, str):
                    for indicator in connection_indicators:
                        if indicator in value:
                            logger.info(f"  ğŸ¯ å‘ç°è¿æ¥æ¨¡å¼åœ¨åˆ— '{col}': {value}")
                            break
    
    # å¦‚æœæœ‰å¤šåˆ—ï¼Œå°è¯•åˆ†æå…³ç³»
    if len(df.columns) >= 2:
        logger.info("  ğŸ” å°è¯•åˆ†æåˆ—ä¹‹é—´çš„å…³ç³»...")
        
        # æŸ¥æ‰¾å¯èƒ½çš„æº-ç›®æ ‡å¯¹
        for i, col1 in enumerate(df.columns):
            for j, col2 in enumerate(df.columns):
                if i != j and df[col1].dtype == 'object' and df[col2].dtype == 'object':
                    # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸åŒçš„å€¼ï¼ˆå¯èƒ½è¡¨ç¤ºè¿æ¥å…³ç³»ï¼‰
                    common_values = set(df[col1].dropna()) & set(df[col2].dropna())
                    if common_values and len(common_values) > 1:
                        logger.info(f"  ğŸ”— '{col1}' å’Œ '{col2}' æœ‰å…±åŒå€¼: {list(common_values)[:5]}...")

def main():
    """ä¸»å‡½æ•°"""
    file_path = "aspen_flowsheet.xlsx"
    
    logger.info("=" * 60)
    logger.info("ğŸš€ å¼€å§‹åˆ†æ Aspen Flowsheet æ–‡ä»¶")
    logger.info("=" * 60)
    
    # è¯»å–å¹¶åˆ†ææ–‡ä»¶
    data = read_flowsheet_excel(file_path)
    
    if data:
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“‹ æ–‡ä»¶åˆ†æå®Œæˆ!")
        logger.info("=" * 60)
        
        # æä¾›æ•°æ®è®¿é—®æ€»ç»“
        logger.info("\nğŸ“ˆ æ•°æ®æ€»ç»“:")
        for sheet_name, df in data.items():
            logger.info(f"  å·¥ä½œè¡¨ '{sheet_name}': {df.shape[0]} è¡Œ, {df.shape[1]} åˆ—")
    else:
        logger.error("âŒ æ–‡ä»¶åˆ†æå¤±è´¥")

if __name__ == "__main__":
    main()
