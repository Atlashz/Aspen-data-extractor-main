#!/usr/bin/env python3
"""
æµè‚¡åˆ†ç±»å’Œæ ‡ç­¾åŒ–è„šæœ¬
å¯¹Aspen Plusæå–çš„æµè‚¡è¿›è¡Œåˆ†ç±»ï¼šåŸæ–™ã€è¿‡ç¨‹ã€äº§å“
"""

import sqlite3
import json
import pandas as pd
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import re

class StreamCategory(Enum):
    """æµè‚¡åˆ†ç±»æšä¸¾"""
    RAW_MATERIAL = "åŸæ–™"          # Raw materials/feeds
    PROCESS = "è¿‡ç¨‹"               # Process streams
    PRODUCT = "äº§å“"               # Products
    UTILITY = "å…¬ç”¨å·¥ç¨‹"           # Utilities
    RECYCLE = "å¾ªç¯"               # Recycle streams
    WASTE = "åºŸæ–™"                 # Waste streams
    INTERMEDIATE = "ä¸­é—´äº§ç‰©"      # Intermediate products
    HOT_UTILITY = "çƒ­å…¬ç”¨å·¥ç¨‹"     # Hot utility streams (steam, hot oil, etc.)
    COLD_UTILITY = "å†·å…¬ç”¨å·¥ç¨‹"    # Cold utility streams (cooling water, refrigerant, etc.)

@dataclass
class StreamClassification:
    """æµè‚¡åˆ†ç±»ç»“æœ"""
    name: str
    category: StreamCategory
    sub_category: str = ""
    confidence: float = 1.0
    reasoning: List[str] = None
    
    def __post_init__(self):
        if self.reasoning is None:
            self.reasoning = []

class StreamClassifier:
    """
    æµè‚¡åˆ†ç±»å™¨
    åŸºäºæµè‚¡åç§°ã€ç»„æˆã€å·¥è‰ºæ¡ä»¶ç­‰ä¿¡æ¯è¿›è¡Œåˆ†ç±»
    """
    
    def __init__(self):
        # å®šä¹‰åˆ†ç±»è§„åˆ™
        self.classification_rules = {
            StreamCategory.RAW_MATERIAL: {
                'name_patterns': [
                    r'.*feed.*', r'.*raw.*', r'.*input.*', r'.*makeup.*',
                    r'bfg.*', r'.*co2.*feed.*', r'h2.*makeup.*', r'fresh.*'
                ],
                'composition_indicators': {
                    'high_inerts': ['N2', 'AR'],  # é«˜æƒ°æ€§æ°”ä½“å«é‡
                    'raw_materials': ['CO', 'CO2', 'H2', 'CH4']
                },
                'temperature_range': (15, 100),  # é€šå¸¸è¾ƒä½æ¸©åº¦
                'pressure_range': (1, 10)       # é€šå¸¸è¾ƒä½å‹åŠ›
            },
            
            StreamCategory.PRODUCT: {
                'name_patterns': [
                    r'.*product.*', r'.*meoh.*', r'.*methanol.*', r'.*water.*product.*',
                    r'.*outlet.*', r'.*final.*'
                ],
                'composition_indicators': {
                    'high_product': ['CH3OH', 'H2O'],  # é«˜äº§å“æµ“åº¦
                    'product_components': ['CH3OH']
                },
                'temperature_range': (20, 200),
                'pressure_range': (1, 60)
            },
            
            StreamCategory.RECYCLE: {
                'name_patterns': [
                    r'.*recycle.*', r'.*recirc.*', r'.*return.*', r'.*loop.*'
                ],
                'composition_indicators': {
                    'recycle_components': ['H2', 'CO', 'CO2', 'CH4'],
                    'low_inerts': ['N2']
                },
                'temperature_range': (30, 300),
                'pressure_range': (10, 60)
            },
            
            StreamCategory.PROCESS: {
                'name_patterns': [
                    r'rxn.*', r'reactor.*', r'.*out.*', r'.*in.*', r's\d+.*', r'.*mix.*'
                ],
                'composition_indicators': {
                    'mixed_components': ['CO', 'CO2', 'H2', 'CH3OH', 'H2O']
                },
                'temperature_range': (100, 350),
                'pressure_range': (20, 60)
            },
            
            StreamCategory.UTILITY: {
                'name_patterns': [
                    r'.*utility.*', r'.*service.*'
                ],
                'composition_indicators': {
                    'utility_components': ['H2O', 'STEAM']
                },
                'temperature_range': (10, 400),
                'pressure_range': (1, 100)
            },
            
            StreamCategory.HOT_UTILITY: {
                'name_patterns': [
                    r'.*steam.*', r'.*hot.*oil.*', r'.*hot.*water.*', r'.*heating.*',
                    r'.*hot.*utility.*', r'.*thermal.*oil.*', r'.*dowtherm.*'
                ],
                'composition_indicators': {
                    'steam_components': ['H2O', 'STEAM'],
                    'thermal_oil_components': ['THERMOIL', 'DOWTHERM']
                },
                'temperature_range': (120, 500),  # Hot utilities are typically high temperature
                'pressure_range': (1, 50)
            },
            
            StreamCategory.COLD_UTILITY: {
                'name_patterns': [
                    r'.*cooling.*water.*', r'.*cold.*water.*', r'.*chilled.*',
                    r'.*refrigerant.*', r'.*coolant.*', r'.*cold.*utility.*'
                ],
                'composition_indicators': {
                    'cooling_water': ['H2O'],
                    'refrigerants': ['NH3', 'R134A', 'R410A', 'PROPANE']
                },
                'temperature_range': (-50, 40),  # Cold utilities are typically low temperature
                'pressure_range': (1, 20)
            },
            
            StreamCategory.WASTE: {
                'name_patterns': [
                    r'.*waste.*', r'.*purge.*', r'.*vent.*', r'.*blow.*down.*'
                ],
                'composition_indicators': {
                    'waste_indicators': ['N2', 'CH4', 'CO2']
                }
            }
        }
    
    def classify_stream(self, stream_data: Dict) -> StreamClassification:
        """
        å¯¹å•ä¸ªæµè‚¡è¿›è¡Œåˆ†ç±»
        
        Args:
            stream_data: åŒ…å«æµè‚¡ä¿¡æ¯çš„å­—å…¸
            
        Returns:
            StreamClassificationå¯¹è±¡
        """
        name = stream_data.get('name', '').lower()
        temperature = stream_data.get('temperature', 0)
        pressure = stream_data.get('pressure', 0)
        composition = stream_data.get('composition', {})
        
        # è§£æç»„æˆæ•°æ®
        if isinstance(composition, str):
            try:
                composition = json.loads(composition)
            except:
                composition = {}
        
        # è®¡ç®—å„åˆ†ç±»çš„å¾—åˆ†
        scores = {}
        detailed_reasoning = {}
        
        for category, rules in self.classification_rules.items():
            score = 0.0
            reasoning = []
            
            # åç§°åŒ¹é…
            name_score = self._check_name_patterns(name, rules.get('name_patterns', []))
            if name_score > 0:
                score += name_score * 0.4  # åç§°æƒé‡40%
                reasoning.append(f"åç§°åŒ¹é… (å¾—åˆ†: {name_score:.2f})")
            
            # ç»„æˆåŒ¹é…
            comp_score = self._check_composition_indicators(composition, rules.get('composition_indicators', {}))
            if comp_score > 0:
                score += comp_score * 0.4  # ç»„æˆæƒé‡40%
                reasoning.append(f"ç»„æˆåŒ¹é… (å¾—åˆ†: {comp_score:.2f})")
            
            # æ¸©åº¦åŒ¹é…
            temp_score = self._check_temperature_range(temperature, rules.get('temperature_range'))
            if temp_score > 0:
                score += temp_score * 0.1  # æ¸©åº¦æƒé‡10%
                reasoning.append(f"æ¸©åº¦åŒ¹é… (å¾—åˆ†: {temp_score:.2f})")
            
            # å‹åŠ›åŒ¹é…
            pres_score = self._check_pressure_range(pressure, rules.get('pressure_range'))
            if pres_score > 0:
                score += pres_score * 0.1  # å‹åŠ›æƒé‡10%
                reasoning.append(f"å‹åŠ›åŒ¹é… (å¾—åˆ†: {pres_score:.2f})")
            
            scores[category] = score
            detailed_reasoning[category] = reasoning
        
        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„åˆ†ç±»
        if scores:
            best_category = max(scores.keys(), key=lambda k: scores[k])
            confidence = scores[best_category]
            reasoning = detailed_reasoning[best_category]
        else:
            best_category = StreamCategory.PROCESS  # é»˜è®¤åˆ†ç±»
            confidence = 0.3
            reasoning = ["é»˜è®¤åˆ†ç±»"]
        
        # ç¡®å®šå­åˆ†ç±»
        sub_category = self._determine_sub_category(best_category, stream_data)
        
        return StreamClassification(
            name=stream_data.get('name', ''),
            category=best_category,
            sub_category=sub_category,
            confidence=confidence,
            reasoning=reasoning
        )
    
    def _check_name_patterns(self, name: str, patterns: List[str]) -> float:
        """æ£€æŸ¥åç§°æ¨¡å¼åŒ¹é…"""
        for pattern in patterns:
            if re.search(pattern, name, re.IGNORECASE):
                return 1.0
        return 0.0
    
    def _check_composition_indicators(self, composition: Dict[str, float], indicators: Dict[str, List[str]]) -> float:
        """æ£€æŸ¥ç»„æˆæŒ‡ç¤ºå™¨"""
        if not composition or not indicators:
            return 0.0
        
        total_score = 0.0
        indicator_count = 0
        
        for indicator_type, components in indicators.items():
            indicator_count += 1
            
            if indicator_type in ['high_product', 'high_inerts']:
                # æ£€æŸ¥é«˜æµ“åº¦ç»„åˆ†
                max_conc = max([composition.get(comp, 0) for comp in components])
                if max_conc > 0.5:  # æµ“åº¦è¶…è¿‡50%
                    total_score += 1.0
                elif max_conc > 0.2:  # æµ“åº¦è¶…è¿‡20%
                    total_score += 0.6
                elif max_conc > 0.05:  # æµ“åº¦è¶…è¿‡5%
                    total_score += 0.3
            
            elif indicator_type in ['low_inerts']:
                # æ£€æŸ¥ä½æµ“åº¦ç»„åˆ†
                max_conc = max([composition.get(comp, 0) for comp in components])
                if max_conc < 0.1:  # æµ“åº¦ä½äº10%
                    total_score += 0.8
                elif max_conc < 0.3:  # æµ“åº¦ä½äº30%
                    total_score += 0.4
            
            else:
                # æ£€æŸ¥ç»„åˆ†å­˜åœ¨æ€§
                present_count = sum([1 for comp in components if composition.get(comp, 0) > 0.01])
                if present_count > 0:
                    total_score += present_count / len(components)
        
        return total_score / max(1, indicator_count)
    
    def _check_temperature_range(self, temperature: float, temp_range: Optional[Tuple[float, float]]) -> float:
        """æ£€æŸ¥æ¸©åº¦èŒƒå›´"""
        if not temp_range or temperature == 0:
            return 0.0
        
        min_temp, max_temp = temp_range
        if min_temp <= temperature <= max_temp:
            return 1.0
        elif temperature < min_temp:
            # æ¸©åº¦è¿‡ä½çš„æƒ©ç½š
            if temperature >= min_temp - 50:
                return 0.5
        elif temperature > max_temp:
            # æ¸©åº¦è¿‡é«˜çš„æƒ©ç½š
            if temperature <= max_temp + 100:
                return 0.5
        
        return 0.0
    
    def _check_pressure_range(self, pressure: float, pres_range: Optional[Tuple[float, float]]) -> float:
        """æ£€æŸ¥å‹åŠ›èŒƒå›´"""
        if not pres_range or pressure == 0:
            return 0.0
        
        min_pres, max_pres = pres_range
        if min_pres <= pressure <= max_pres:
            return 1.0
        elif pressure < min_pres:
            if pressure >= min_pres - 5:
                return 0.5
        elif pressure > max_pres:
            if pressure <= max_pres + 20:
                return 0.5
        
        return 0.0
    
    def _determine_sub_category(self, category: StreamCategory, stream_data: Dict) -> str:
        """ç¡®å®šå­åˆ†ç±»"""
        name = stream_data.get('name', '').lower()
        composition = stream_data.get('composition', {})
        
        if isinstance(composition, str):
            try:
                composition = json.loads(composition)
            except:
                composition = {}
        
        if category == StreamCategory.RAW_MATERIAL:
            if 'bfg' in name or 'blast' in name:
                return "é«˜ç‚‰ç…¤æ°”"
            elif 'co2' in name:
                return "äºŒæ°§åŒ–ç¢³åŸæ–™"
            elif 'h2' in name:
                return "æ°¢æ°”è¡¥å……"
            else:
                return "å…¶ä»–åŸæ–™"
        
        elif category == StreamCategory.PRODUCT:
            if 'meoh' in name or 'methanol' in name:
                return "ç”²é†‡äº§å“"
            elif 'water' in name:
                return "æ°´äº§å“"
            else:
                return "å…¶ä»–äº§å“"
        
        elif category == StreamCategory.PROCESS:
            if 'rxn' in name or 'reactor' in name:
                return "ååº”å™¨æµè‚¡"
            elif 'mix' in name:
                return "æ··åˆæµè‚¡"
            else:
                return "å·¥è‰ºæµè‚¡"
        
        elif category == StreamCategory.RECYCLE:
            return "å¾ªç¯æ°”"
        
        return ""

def classify_all_streams() -> List[StreamClassification]:
    """å¯¹æ•°æ®åº“ä¸­çš„æ‰€æœ‰æµè‚¡è¿›è¡Œåˆ†ç±»"""
    
    # è¿æ¥æ•°æ®åº“
    conn = sqlite3.connect('aspen_data.db')
    cursor = conn.cursor()
    
    # è·å–æ‰€æœ‰æµè‚¡æ•°æ®
    cursor.execute('''
        SELECT name, temperature, pressure, mass_flow, volume_flow, molar_flow, composition
        FROM aspen_streams
        ORDER BY name
    ''')
    
    streams_data = cursor.fetchall()
    conn.close()
    
    # åˆå§‹åŒ–åˆ†ç±»å™¨
    classifier = StreamClassifier()
    
    # å¯¹æ¯ä¸ªæµè‚¡è¿›è¡Œåˆ†ç±»
    classifications = []
    
    print("ğŸ” æµè‚¡åˆ†ç±»åˆ†æ")
    print("=" * 60)
    
    for stream_row in streams_data:
        name, temp, pres, mass_flow, vol_flow, mol_flow, composition = stream_row
        
        stream_data = {
            'name': name,
            'temperature': temp or 0,
            'pressure': pres or 0,
            'mass_flow': mass_flow or 0,
            'volume_flow': vol_flow or 0,
            'molar_flow': mol_flow or 0,
            'composition': composition or '{}'
        }
        
        # åˆ†ç±»
        classification = classifier.classify_stream(stream_data)
        classifications.append(classification)
        
        # æ‰“å°åˆ†ç±»ç»“æœ
        print(f"\nğŸ“‹ æµè‚¡: {name}")
        print(f"   åˆ†ç±»: {classification.category.value}")
        if classification.sub_category:
            print(f"   å­åˆ†ç±»: {classification.sub_category}")
        print(f"   ç½®ä¿¡åº¦: {classification.confidence:.2f}")
        print(f"   æ¡ä»¶: T={temp}Â°C, P={pres}bar, {mass_flow:.0f}kg/hr")
        
        # æ˜¾ç¤ºä¸»è¦ç»„åˆ†
        if composition:
            try:
                comp_dict = json.loads(composition)
                main_comps = {k: f"{v:.3f}" for k, v in comp_dict.items() if v > 0.01}
                if main_comps:
                    print(f"   ä¸»è¦ç»„åˆ†: {main_comps}")
            except:
                pass
        
        print(f"   åˆ†ç±»ä¾æ®: {', '.join(classification.reasoning)}")
    
    return classifications

def update_database_with_classifications(classifications: List[StreamClassification]):
    """å°†åˆ†ç±»ç»“æœæ›´æ–°åˆ°æ•°æ®åº“"""
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ æ–°åˆ—
    conn = sqlite3.connect('aspen_data.db')
    cursor = conn.cursor()
    
    # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
    cursor.execute("PRAGMA table_info(aspen_streams)")
    columns = [column[1] for column in cursor.fetchall()]
    
    # æ·»åŠ åˆ†ç±»ç›¸å…³åˆ—
    if 'stream_category' not in columns:
        cursor.execute('ALTER TABLE aspen_streams ADD COLUMN stream_category TEXT')
    
    if 'stream_sub_category' not in columns:
        cursor.execute('ALTER TABLE aspen_streams ADD COLUMN stream_sub_category TEXT')
    
    if 'classification_confidence' not in columns:
        cursor.execute('ALTER TABLE aspen_streams ADD COLUMN classification_confidence REAL')
    
    if 'classification_reasoning' not in columns:
        cursor.execute('ALTER TABLE aspen_streams ADD COLUMN classification_reasoning TEXT')
    
    # æ›´æ–°åˆ†ç±»ä¿¡æ¯
    print(f"\nğŸ“ æ›´æ–°æ•°æ®åº“ä¸­çš„æµè‚¡åˆ†ç±»...")
    
    for classification in classifications:
        cursor.execute('''
            UPDATE aspen_streams
            SET stream_category = ?,
                stream_sub_category = ?,
                classification_confidence = ?,
                classification_reasoning = ?
            WHERE name = ?
        ''', (
            classification.category.value,
            classification.sub_category,
            classification.confidence,
            json.dumps(classification.reasoning, ensure_ascii=False),
            classification.name
        ))
    
    conn.commit()
    conn.close()
    
    print(f"âœ… å·²æ›´æ–° {len(classifications)} ä¸ªæµè‚¡çš„åˆ†ç±»ä¿¡æ¯")

def generate_classification_summary(classifications: List[StreamClassification]):
    """ç”Ÿæˆåˆ†ç±»æ±‡æ€»æŠ¥å‘Š"""
    
    print(f"\nğŸ“Š æµè‚¡åˆ†ç±»æ±‡æ€»æŠ¥å‘Š")
    print("=" * 60)
    
    # æŒ‰åˆ†ç±»ç»Ÿè®¡
    category_counts = {}
    for classification in classifications:
        category = classification.category.value
        category_counts[category] = category_counts.get(category, 0) + 1
    
    print(f"æ€»æµè‚¡æ•°: {len(classifications)}")
    print(f"\næŒ‰åˆ†ç±»ç»Ÿè®¡:")
    for category, count in sorted(category_counts.items()):
        percentage = (count / len(classifications)) * 100
        print(f"  {category}: {count} ({percentage:.1f}%)")
    
    # æŒ‰å­åˆ†ç±»ç»Ÿè®¡
    print(f"\nè¯¦ç»†åˆ†ç±»:")
    current_category = None
    for classification in sorted(classifications, key=lambda x: x.category.value):
        if classification.category.value != current_category:
            current_category = classification.category.value
            print(f"\n{current_category}:")
        
        sub_info = f" - {classification.sub_category}" if classification.sub_category else ""
        confidence_info = f" (ç½®ä¿¡åº¦: {classification.confidence:.2f})"
        print(f"  â€¢ {classification.name}{sub_info}{confidence_info}")
    
    # ä½ç½®ä¿¡åº¦åˆ†ç±»
    low_confidence = [c for c in classifications if c.confidence < 0.6]
    if low_confidence:
        print(f"\nâš ï¸  ä½ç½®ä¿¡åº¦åˆ†ç±» (éœ€è¦äººå·¥ç¡®è®¤):")
        for classification in low_confidence:
            print(f"  â€¢ {classification.name}: {classification.category.value} "
                  f"(ç½®ä¿¡åº¦: {classification.confidence:.2f})")

def export_classification_results(classifications: List[StreamClassification], filename: str = None):
    """å¯¼å‡ºåˆ†ç±»ç»“æœåˆ°Excelæ–‡ä»¶"""
    
    if filename is None:
        from datetime import datetime
        filename = f"stream_classification_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
    
    # å‡†å¤‡æ•°æ®
    export_data = []
    for classification in classifications:
        export_data.append({
            'æµè‚¡åç§°': classification.name,
            'åˆ†ç±»': classification.category.value,
            'å­åˆ†ç±»': classification.sub_category,
            'ç½®ä¿¡åº¦': classification.confidence,
            'åˆ†ç±»ä¾æ®': '; '.join(classification.reasoning)
        })
    
    # åˆ›å»ºDataFrameå¹¶å¯¼å‡º
    df = pd.DataFrame(export_data)
    
    try:
        df.to_excel(filename, index=False, engine='openpyxl')
        print(f"\nğŸ“Š åˆ†ç±»ç»“æœå·²å¯¼å‡ºåˆ°: {filename}")
        return True
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ æµè‚¡åˆ†ç±»å’Œæ ‡ç­¾åŒ–ç³»ç»Ÿ")
    print("=" * 50)
    
    # æ‰§è¡Œåˆ†ç±»
    classifications = classify_all_streams()
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    generate_classification_summary(classifications)
    
    # è¯¢é—®æ˜¯å¦æ›´æ–°æ•°æ®åº“
    response = input(f"\næ˜¯å¦å°†åˆ†ç±»ç»“æœæ›´æ–°åˆ°æ•°æ®åº“? (y/n): ").lower()
    if response == 'y':
        update_database_with_classifications(classifications)
        
        # éªŒè¯æ›´æ–°
        print(f"\nğŸ” éªŒè¯æ•°æ®åº“æ›´æ–°...")
        conn = sqlite3.connect('aspen_data.db')
        df = pd.read_sql_query('''
            SELECT name, stream_category, stream_sub_category, classification_confidence
            FROM aspen_streams
            ORDER BY stream_category, name
        ''', conn)
        conn.close()
        
        print(f"\næ›´æ–°åçš„æµè‚¡åˆ†ç±»:")
        print(df.to_string(index=False))
    
    # è¯¢é—®æ˜¯å¦å¯¼å‡ºExcel
    response = input(f"\næ˜¯å¦å¯¼å‡ºåˆ†ç±»ç»“æœåˆ°Excel? (y/n): ").lower()
    if response == 'y':
        export_classification_results(classifications)
    
    print(f"\nğŸ‰ æµè‚¡åˆ†ç±»å®Œæˆ!")
